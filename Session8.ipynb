{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee8e051",
   "metadata": {},
   "source": [
    "# Applied Digital Citizen Science\n",
    "## Session 8\n",
    "\n",
    "DISCLOSURE: Parts of the code for this notebook were created with GitHub CoPilot, and disclosed as such. All code has been tested by the lecturers.\n",
    "\n",
    "See Canvas for details about usage of Generative AI in assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8b3eea",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bd5eeb5",
   "metadata": {},
   "source": [
    "## Objectives for Session 8\n",
    "\n",
    "The code here will be relevant for cleaning, aggregating and formatting the data that you will use for your written report. \n",
    "\n",
    "The sections of code in this notebook are self-contained, and you may not need to use everything all the time. The objectives of this session are:\n",
    "\n",
    "1. Combining the raw dataset (generated with the code from session 6) with self-reports\n",
    "2. Combining the raw dataset (generated with the code from session 6) with the YouTube Data Tools\n",
    "3. Aggregating the dataset at the correct level depending on your RQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4917a4c",
   "metadata": {},
   "source": [
    "## 1. Combining the donated dataset with self-reports\n",
    "\n",
    "For these steps, you first need to:\n",
    "1. Run the steps in Session 6 that generate the consolidated datasets (for example on watch or search)\n",
    "2. Download the data from Qualtrics as Excel\n",
    "3. Make sure all datasets are in the same folder as the script you are running\n",
    "\n",
    "The example below uses the watch history. You can simply load another dataset (e.g., search) and run the same steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c31634d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac0eaeb",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "donated_data = pd.read_excel('Watch.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ccae30",
   "metadata": {},
   "outputs": [],
   "source": [
    "donated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7467c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_reports = pd.read_excel('ADCS-2025-demo2_September+21,+2025_17.03.xlsx', skiprows=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6628ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1f941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_participant_id(text):\n",
    "    text = text.split('_')\n",
    "    if len(text) > 2:\n",
    "        return text[2]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c195d851",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_reports['participantid'] = self_reports['participant'].apply(extract_participant_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e6aabc",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ea9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "donated_data['participantid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc66df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_reports['participantid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6125795a",
   "metadata": {},
   "source": [
    "### Options for merging the data\n",
    "\n",
    "- We could merge the data at the video level (i.e., each participant appears 20 times in the dataset)\n",
    "- We could merge the data at participant level (i.e., each participant appears once in the dataset)\n",
    "\n",
    "Which way to choose? Depends on the RQ.\n",
    "\n",
    "For now, we will have examples in both ways - both at the video level, and at the participant level."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f394546",
   "metadata": {},
   "source": [
    "### Merging the data at the video level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a71a583",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_video_level = pd.merge(donated_data, self_reports, on='participantid', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b166b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_video_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867498a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_video_level['participantid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c80b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "self_reports['participantid'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257bd9b",
   "metadata": {},
   "source": [
    "For discussion: Do we have the same participants in both? If not, why?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8c0a67",
   "metadata": {},
   "source": [
    "### Merging at the participant level\n",
    "\n",
    "For this dataset, each participant will appear only once. Considering that in the videos dataset each participant appears multiple times, we will then need to decide how do we aggregate the videos dataset at participant level.\n",
    "\n",
    "In this example, I will use the number of videos watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60576d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_watched = pd.pivot_table(donated_data, index='participantid', values='Link', aggfunc='count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3a6edc",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_watched"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf22be4a",
   "metadata": {},
   "source": [
    "For discussion: Why do I only have 19 videos, if each participant appears 20 times in the donated dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d65fa75",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_participant_level = pd.merge(self_reports, videos_watched, on='participantid', how='left').rename(columns={'Link': 'videos_watched'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39a1e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_participant_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8296d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_participant_level.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752de9de",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_participant_level['videos_watched'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8220f7b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c4857e8e",
   "metadata": {},
   "source": [
    "For discussion: Why do some participants have a missing value in videos watched?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e18a8c2",
   "metadata": {},
   "source": [
    "### Exporting the datasets\n",
    "\n",
    "After completing the work, you may want to export the appropriate datasets. The example below has the dataset_participant_level as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdebb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_participant_level.to_excel('dataset_participant_level.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bb322",
   "metadata": {},
   "source": [
    "## 2. Combining the donated dataset with YouTube Data Tools\n",
    "\n",
    "For these steps, you first need to:\n",
    "1. Run the steps in Session 6 that generate the consolidated datasets (for example on watch or search)\n",
    "2. Make sure all datasets are in the same folder as the script you are running\n",
    "\n",
    "The example below uses the watch history. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_history = pd.read_excel('Watch.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519055dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31d4ec",
   "metadata": {},
   "source": [
    "We now need to get the video_ids from the YouTube videos. Remember the code we saw on Session 4. \n",
    "\n",
    "(Disclosure: the code below was created with the help of CoPilot, and was updated for this session)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cace4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_youtube_video_id(url):\n",
    "    url = str(url)\n",
    "    if 'youtube.com/watch?v=' in url:\n",
    "        return url.split('v=')[1].split('&')[0]\n",
    "    elif 'youtu.be/' in url:\n",
    "        return url.split('youtu.be/')[1].split('?')[0]\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_history['videoid'] = watch_history['Link'].apply(extract_youtube_video_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceac092",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_history['videoid']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b2345",
   "metadata": {},
   "source": [
    "Now I will print the video ids in a format that I can simply then copy and paste to reuse at the YouTube Data Tools interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32daa41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for videoid in watch_history['videoid'].unique():\n",
    "    if len(str(videoid)) > 4:\n",
    "        print(videoid + ',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7c0acc",
   "metadata": {},
   "source": [
    "I will now go to the YouTube Data Tools and use these ids to generate a report with information about each of these videos (using the video list module). After this is done, I will download the report from YouTube Data Tools to my own computer, and save the file to the same folder as where this script and other relevant files are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2148da",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_report = pd.read_csv('videolist_seeds19_2025_09_21-16_11_44.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ab163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30aa1dd6",
   "metadata": {},
   "source": [
    "Merging both datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_history_details = pd.merge(watch_history, youtube_report, left_on='videoid', right_on='videoId', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10724d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_history_details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88a1211",
   "metadata": {},
   "source": [
    "### Exporting the datasets\n",
    "\n",
    "After completing the work, you may want to export the appropriate datasets. The example below has the dataset_participant_level as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9991cd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_history_details.to_excel('watch_history_details.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea914460",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
