{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ee8e051",
   "metadata": {},
   "source": [
    "# Applied Digital Citizen Science\n",
    "## Session 6\n",
    "\n",
    "DISCLOSURE: Parts of the code for this notebook were created with GitHub CoPilot, and disclosed as such. All code has been tested by the lecturers.\n",
    "\n",
    "See Canvas for details about usage of Generative AI in assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bd5eeb5",
   "metadata": {},
   "source": [
    "## Objectives for Session 6\n",
    "\n",
    "1. Access the data storage\n",
    "2. Read and consolidate the donated files into a (raw) dataset\n",
    "3. Inspect, minimise and (if needed) anonymize the (raw) dataset\n",
    "4. Save the processed dataset to your own computer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84095450",
   "metadata": {},
   "source": [
    "## Importing required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a230b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4917a4c",
   "metadata": {},
   "source": [
    "## Accessing the data storage\n",
    "\n",
    "Please see on Canvas the details on data storage and data management rules. When ready, update the information on the variable \"path\", below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0dd1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a2bb322",
   "metadata": {},
   "source": [
    "## Consolidating the files\n",
    "\n",
    "The code below uses the library \"os\" to list all files in the path you indicated above, and store them in a list called files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d424db52",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = os.listdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519055dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac31d4ec",
   "metadata": {},
   "source": [
    "The following steps will create two datasets:\n",
    "* Onboarding: Information about participant activity in the first page within Port (i.e., the general informed consent/about the study)\n",
    "* YouTube: Data donation (and/or declining of consent) after data visualisation by participants.\n",
    "\n",
    "Please note that you need to specify which \"status\" for the dataset you want, e.g., \"test\", \"survey\" or any other status code. The function will collect this information from the filename."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cace4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(path, status):\n",
    "    onboarding = pd.DataFrame()\n",
    "    datasets = {}\n",
    "    \n",
    "    for file in files:\n",
    "        status = file.split('_participant=')[1].split('_')[1]\n",
    "        group = file.split('_participant=')[1].split('_')[0]\n",
    "        participantid = file.split('_participant=')[1].split('_')[2]\n",
    "        filetype = file.split('_source=')[1]\n",
    "\n",
    "        if \"onboarding\" in filetype:\n",
    "            tmp = pd.read_json(os.path.join(path, file), lines=True)\n",
    "            tmp['group'] = group\n",
    "            tmp['participantid'] = participantid\n",
    "            onboarding = pd.concat([onboarding, tmp], ignore_index=True)\n",
    "\n",
    "        if \"YouTube\" in filetype:\n",
    "            yt = json.load(open(os.path.join(path, file), encoding='utf-8'))\n",
    "            \n",
    "            for item in yt:\n",
    "                keys = item.keys()\n",
    "                for key in keys:\n",
    "                    tmp_yt = pd.json_normalize(item[key])\n",
    "                    tmp_yt['group'] = group\n",
    "                    tmp_yt['participantid'] = participantid\n",
    "                    if key not in datasets:\n",
    "                        datasets[key] = tmp_yt\n",
    "                    else:\n",
    "                        datasets[key] = pd.concat([datasets[key],tmp_yt], ignore_index=True)\n",
    "\n",
    "    \n",
    "    return onboarding, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d2c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding, youtube = create_datasets(path, \"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dceac092",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32daa41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b2148da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdf2122",
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube['youtube_kijkgeschiedenis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10724d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch = youtube['youtube_kijkgeschiedenis']\n",
    "search = youtube['youtube_zoekgeschiedenis']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f43c7c",
   "metadata": {},
   "source": [
    "## Inspecting the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59b9b3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf73b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eff0f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "onboarding.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97978085",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370bf2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71fbb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch.iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9892100f",
   "metadata": {},
   "source": [
    "## Discussion: Anonymisation and Minimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13b451d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7263347",
   "metadata": {},
   "source": [
    "## Exporting the datasets to our own computers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7125438b",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch.to_excel('watch.xlsx')\n",
    "search.to_excel('search.xlsx')\n",
    "onboarding.to_excel('logs.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
